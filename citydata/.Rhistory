knn3Train(train, test, cl, k = 5, prob = TRUE)
cl
shiny::runApp('Shiny')
runApp("App-1", display.mode = "showcase")
runApp("ui.R", display.mode = "showcase")
getws()
getwd()
setwd("~/Shiny")
getwd()
runApp("ui.R", display.mode = "showcase")
setwd("C:/Users/oweni/OneDrive/Documents/")
runApp("Shiny", display.mode = "showcase")
shiny::runApp('Shiny')
"asdf"=="asdf"
getwd()
setwd("C:\\Users\\oweni\\OneDrive\\Documents")
library(shiny)
runApp(shiny)
runApp(Shiny)
getwd()
runApp(Shiny)
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
runApp("Shiny", display.mode = "showcase")
shiny::runApp('Shiny')
shiny::runApp('Shiny')
shiny::runApp('Shiny')
counties <- readRDS("Shiny/data/counties.rds")
head(counties)
install.packages("maps")
?pmax
library(maps)
library(mapproj)
source("Shiny/helpers.R")
source("census-app/helpers.R")
percent_map(counties$white, "darkgreen", "% white")
shiny::runApp('census-app')
shiny::runApp('census-app')
"Percent White" = list(counties$white, "darkgreen", "% White")
install.packages("quantmod")
runApp('stockVis')
Sys.setenv()
Sys.setenv(LANG = "en")
Sys.setenv()
shiny::runApp('census-app')
runApp('stockVis')
help("Sys.setlocale")
Sys.getlocale()
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
Sys.getlocale()
runApp('stockVis')
runApp('stockVis')
?chartSeries
shiny::runApp('stockVis')
shiny::runApp('stockVis')
9.8*1*2
sqrt(19.6)
5*200/1
5e6
5e6+1
5e8/15000/500
？log
?log
log(5e8,250)
5e8/15000
install.packages(c("boot", "ggplot2", "gridExtra", "gtable", "Hmisc", "htmlwidgets", "lme4", "munsell", "mvtnorm", "nlme", "nnet", "openssl", "quantreg", "RcppEigen", "rmarkdown", "RNetCDF", "scales", "shiny", "sp", "vegan", "xtable"))
install.packages("RcppEigen")
??qmplot
install.packages("NLP")
library(devtools)
install_github("mannau/tm.plugin.sentiment")
library(tm.plugin.sentiment)
require(tm.plugin.webmining)
install.packages("tm.plugin.webmining")
require(tm.plugin.webmining)
corp = WebCorpus(GoogleFinanceSource("AAPL"))
# score corpus
corp <- score(corp)
sentixts <- metaXTS(corp)
# chart sentiment scores
chartSentiment(sentixts)
log(5e10,500)
log(5e10,500)
log(5e8,500)
5e8/15000/500
72*15000
require(devtools)
install_github('ramnathv/rCharts@dev')
install_github('ramnathv/rMaps')
install_github('ramnathv/rCharts@dev')
install.packages("base64enc")
install_github('ramnathv/rCharts@dev')
install_github('ramnathv/rMaps')
library(rMaps)
library(Quandl)
install.packages("Quandl")
library(reshape2)
library(Quandl)
library(knitr)
library(plyr)
library(dplyr)
library(rCharts)
vcData = Quandl("FBI_UCR/USCRIME_TYPE_VIOLENTCRIMERATE")
class(vcData)
kable(head(vcData[,1:9]), format = 'html', table.attr = "class=nofluid")
datm = melt(vcData, 'Year', # "Year" here set as "id variable"
variable.name = 'State',
# the rest variables are those you want to stack as 'State'
value.name = 'Crime')
# values are named with 'Crime' and form the new column
datm2 = subset(na.omit(datm), #handle missing values: omit
!(State %in% c("United States", "District of Columbia")))
which(is.na(datm))
temp = c(as.matrix(datm))
temp[which(is.na(datm))]
datm = datm2
rm(datm2)
datm2 = transform(datm,
State = state.abb[match(as.character(State), state.name)],
fillKey = cut(Crime, quantile(Crime, seq(0, 1, 1/5)), labels = LETTERS[1:5]),
Year = as.numeric(substr(Year, 1, 4))) #extract the 4 characters of each 'Year'
# Now you have a new table to embed
kable(head(datm2), format = 'html', table.attr = "class=nofluid")
#format fill for map
fills = setNames( #Set the Names in an Object
c(RColorBrewer::brewer.pal(5, 'YlOrRd'), 'white'),
c(LETTERS[1:5], 'defaultFill')
)
dat2 = dlply(na.omit(datm2), "Year", function(x)
{
y = toJSONArray2(x, json=FALSE) #json=FALSE to get the large list; json=TRUE to get a json array
names(y) = lapply(y, '[[', 'State') #lapply also return a list
# this step extracts the state abbreviations
return(y)
})
# Now data is ready --> let's plot
#Simplest rChart example: static map (other option: ggmap)
options(rcharts.cdn = TRUE) #option to have interactive plot
map = Datamaps$new()
map$set(
dom = 'chart_1',
scope = 'usa',
fills = fills,
data = dat2[[1]],
legend = TRUE,
labels = TRUE
)
map
install.packages("leaflet")
library(leaflet)
m = leaflet() %>% # pipe operator (%>%)
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=-73.9613, lat=40.8084, popup="Columbia University")
m
m = leaflet()
m = addTiles(m)
m = addMarkers(m, lng=-73.9613, lat=40.8084, popup="Columbia University")
m
library(sp)
Sr1 = Polygon(cbind(c(2, 4, 4, 1, 2), c(2, 3, 5, 4, 2)))
Sr2 = Polygon(cbind(c(5, 4, 2, 5), c(2, 3, 2, 2)))
Sr3 = Polygon(cbind(c(4, 4, 5, 10, 4), c(5, 3, 2, 5, 5)))
Sr4 = Polygon(cbind(c(5, 6, 6, 5, 5), c(4, 4, 3, 3, 4)), hole = TRUE)
Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr4, Sr3), "s3/4")
SpP = SpatialPolygons(list(Srs1, Srs2, Srs3), 1:3)
leaflet(height = "300px") %>% addPolygons(data = SpP)
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
maptristates = map('state', region = c('new york', 'new jersey', 'penn'), fill = TRUE, plot = FALSE)
leaflet(data = maptristates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(3, alpha = NULL), stroke = FALSE)
m <- leaflet() %>% setView(lng=-73.9613, lat=40.8084, zoom = 10)
m %>% addTiles()
m %>% addProviderTiles("Stamen.Toner")
m %>% addProviderTiles("CartoDB.Positron")
leaflet() %>% addTiles() %>% setView(-73.9613, 40.8084, zoom = 4) %>%
addWMSTiles(
"http://mesonet.agron.iastate.edu/cgi-bin/wms/nexrad/n0r.cgi",
layers = "nexrad-n0r-900913",
options = WMSTileOptions(format = "image/png", transparent = TRUE),
attribution = "Weather data Â© 2012 IEM Nexrad"
)
m %>% addProviderTiles("MtbMap") %>%
addProviderTiles("Stamen.TonerLines",
options = providerTileOptions(opacity = 0.35)
) %>%
addProviderTiles("Stamen.TonerLabels")
data(quakes)
leaflet(data = quakes[1:20,]) %>% addTiles() %>%
addMarkers(~long, ~lat, popup = ~as.character(mag))
myIcon <- makeIcon(
iconUrl = "https://cdn0.iconfinder.com/data/icons/disaster-blaster/250/Volcanic-eruption-512.png",
iconWidth = 40, iconHeight = 45,
iconAnchorX = 22, iconAnchorY = 94
)
leaflet(data = quakes[1:20,]) %>% addTiles() %>%
addMarkers(~long, ~lat, icon = myIcon)
quakes1 <- quakes[1:20,]
myIcons <- icons(
iconUrl = ifelse(quakes1$mag < 4.6,
"https://cdn3.iconfinder.com/data/icons/basic-mobile-part-2/512/volcano-128.png",
"https://cdn0.iconfinder.com/data/icons/disaster-blaster/250/Volcanic-eruption-512.png"
),
iconWidth = 40, iconHeight = 45,
iconAnchorX = 22, iconAnchorY = 94
)
leaflet(data = quakes1) %>% addTiles() %>%
addMarkers(~long, ~lat, icon = myIcons)
oceanIcons <- iconList(
ship = makeIcon(iconUrl="https://image.freepik.com/free-icon/ocean-transportation_318-61537.png",
iconWidth = 40, iconHeight = 40),
pirate = makeIcon(iconUrl = "https://anthonylugo.files.wordpress.com/2013/03/pirate.jpg",
iconWidth = 40, iconHeight = 40)
)
df <- sp::SpatialPointsDataFrame(
cbind(
(runif(20) - .5) * 10 - 90.620130,  # lng
(runif(20) - .5) * 3.8 + 25.638077  # lat
),
data.frame(type = factor(
ifelse(runif(20) > 0.75, "pirate", "ship"),
c("ship", "pirate")
))
)
leaflet(df) %>% addTiles() %>%
# Select from oceanIcons based on df$type
addMarkers(icon = ~oceanIcons[type])
leaflet(df) %>% addTiles() %>% addCircleMarkers()
pal <- colorFactor(c("navy", "red"), domain = c("ship", "pirate"))
leaflet(df) %>% addTiles() %>%
addCircleMarkers(
radius = ~ifelse(type == "ship", 6, 10),
color = ~pal(type),
stroke = FALSE, fillOpacity = 0.5
)
leaflet(quakes) %>% addTiles() %>% addMarkers(
clusterOptions = markerClusterOptions()
)
library(rMaps)
L2 = Leaflet$new()
# setView() sets the center of the map view and the zoom level;
L2$setView(c(29.7632836,  -95.3632715), 10)
L2$tileLayer(provider = "MapQuestOpen.OSM")
L2
data(crime, package = 'ggmap')
library(plyr)
crime_dat = ddply(crime, .(lat, lon), summarise, count = length(address))
crime_dat = toJSONArray2(na.omit(crime_dat), json = F, names = F)
cat(rjson::toJSON(crime_dat[1:2]))
L2$addAssets(jshead = c("http://leaflet.github.io/Leaflet.heat/dist/leaflet-heat.js"))
L2$setTemplate(afterScript = sprintf("
<script>
var addressPoints = %s
var heat = L.heatLayer(addressPoints).addTo(map)
</script>
", rjson::toJSON(crime_dat)
))
L2
options(rcharts.cdn = TRUE) #option to have interactive plot
map = Datamaps$new()
map$set(
dom = 'chart_1',
scope = 'usa',
fills = fills,
data = dat2[[1]],
legend = TRUE,
labels = TRUE
)
map
dat2[1]
m = leaflet() %>% # pipe operator (%>%)
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=-73.9613, lat=40.8084, popup="Columbia University")
m
library(sp)
Sr1 = Polygon(cbind(c(2, 4, 4, 1, 2), c(2, 3, 5, 4, 2)))
Sr2 = Polygon(cbind(c(5, 4, 2, 5), c(2, 3, 2, 2)))
Sr3 = Polygon(cbind(c(4, 4, 5, 10, 4), c(5, 3, 2, 5, 5)))
Sr4 = Polygon(cbind(c(5, 6, 6, 5, 5), c(4, 4, 3, 3, 4)), hole = TRUE)
Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr4, Sr3), "s3/4")
SpP = SpatialPolygons(list(Srs1, Srs2, Srs3), 1:3)
leaflet(height = "300px") %>% addPolygons(data = SpP)
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
maptristates = map('state', region = c('new york', 'new jersey', 'penn'), fill = TRUE, plot = FALSE)
leaflet(data = maptristates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(3, alpha = NULL), stroke = FALSE)
m <- leaflet() %>% setView(lng=-73.9613, lat=40.8084, zoom = 10)
m %>% addTiles()
m %>% addProviderTiles("Stamen.Toner")
m %>% addProviderTiles("CartoDB.Positron")
leaflet() %>% addTiles() %>% setView(-73.9613, 40.8084, zoom = 4) %>%
addWMSTiles(
"http://mesonet.agron.iastate.edu/cgi-bin/wms/nexrad/n0r.cgi",
layers = "nexrad-n0r-900913",
options = WMSTileOptions(format = "image/png", transparent = TRUE),
attribution = "Weather data Â© 2012 IEM Nexrad"
)
library(lattice)
library(devtools)
install_github("vqv/ggbiplot")
data(cars)
View(cars)
data("mtcars")
View(mtcars)
mtcars$model = row.names(mtcars)
str(mtcars)
mtcars[mtcars$model == "Valiant",]$model = 1
normalize(cars)
shiny::runApp('GitHub/EDAV_proj3/shiny code')
install.packages("plotly")
shiny::runApp('GitHub/EDAV_proj3/shiny code')
install.packages("choroplethr")
shiny::runApp('GitHub/EDAV_proj3/shiny code')
install.packages("choroplethrZip")
library(devtools)
install_github('arilamstein/choroplethrZip@v1.5.0')
library(devtools)
install.packages("devtools")
library(devtools)
install_github('arilamstein/choroplethrZip@v1.5.0')
shiny::runApp('GitHub/EDAV_proj3/shiny code')
install.packages("DT")
shiny::runApp('GitHub/EDAV_proj3/shiny code')
shiny::runApp('GitHub/EDAV_proj3/shiny code')
city_data = read.csv("NYC_data.csv")
setwd("C:/Users/oweni/OneDrive/Documents/GitHub/EDAV_proj3/citydata")
city_data = read.csv("NYC_data.csv")
View(city_data)
str(city_data)
met = citu_data$metro
met = city_data$metro
ggplot(aes(x = metro))+geom_histogram(stat = "bin")
library(ggplot2)
ggplot(aes(x = metro))+geom_histogram(stat = "bin")
ggplot(city_data,aes(x = metro))+geom_histogram(stat = "bin")
ggplot(city_data,aes(x = metro))+geom_histogram(stat = "bin",binwidth=1)
qplot(city_data, data=metro,geom="histogram", binwidth=1)
qplot(metro, data=city_data,geom="histogram", binwidth=1)
hist(city_data$metro)
hist(city_data$metro,bandwidth = 1)
?hist
qplot(metro, data=city_data,geom="histogram", binwidth=1)
met = city_data[city_data$metro>0,]
ggplot(met,aes(x = metro))+geom_histogram(stat = "bin",binwidth=1)
city_data = read.csv("NYC_data.csv")
library(ggplot2)
# analysis to set thresholds
ggplot(city_data,aes(x = metro))+geom_histogram(stat = "bin",binwidth=1)+
ggtitle(distribution of number of )
# analysis to set thresholds
ggplot(city_data,aes(x = metro))+geom_histogram(stat = "bin",binwidth=1)+
ggtitle("distribution of number of metro stations")
View(city_data)
city_data = read.csv("NYC_data.csv")
ggplot(city_data,aes(x = metro))+geom_histogram(stat = "bin",binwidth=1)+
ggtitle("Distribution of Number of Metro stations")
?quantile
quantile(city_data$metro,probs = 0.33)
quantile(city_data$metro,probs = 0.67)
city_data$metro_convenience = "inconvenient"
city_data$metro_convenience[city_data$metro>=quantile(city_data$metro,probs = 0.67)] = "convenient"
city_data$metro_convenience[city_data$metro<quantile(city_data$metro,probs = 0.67) & city_data$metro>=quantile(city_data$metro,probs = 0.33)] = "intermediate"
crime = city_data$crime_rate
city_data = read.csv("NYC_data.csv")
city_data = city_data[city_data$population>0,]
library(ggplot2)
ggplot(city_data,aes(x = metro))+geom_histogram(stat = "bin",binwidth=1)+
ggtitle("Distribution of Number of Metro stations")
met33 = quantile(city_data$metro,probs = 0.33)
met67 = quantile(city_data$metro,probs = 0.67)
city_data$metro_convenience = "inconvenient"
city_data$metro_convenience[city_data$metro>=met67] = "convenient"
city_data$metro_convenience[city_data$metro<met67 & city_data$metro>=met33] = "intermediate"
crime33 = quantile(city_data$crime_rate,probs = 0.33)
crime33
crime67
crime67 = quantile(city_data$crime_rate,probs = 0.67)
crime67
city_data$security = "unsafe"
city_data$security = "unsafe"
city_data$security[city_data$crime_rate>=crime67] = "safe"
city_data$security[city_data$crime_rate<crime67 & city_data$crime_rate>=crime33] = "intermediate"
complain = read.csv("complain data(1,4,7,10).csv")
library(dplyr)
?group_bby
?group_by
head(complain)
complain_zip = summarize(group_comp,complain = n())
group_comp = group_by(complain,zip)
complain_zip = summarize(group_comp,complain = n())
View(complain_zip)
View(city_data)
View(complain_zip)
View(city_data)
names(complain_zip)[1] = "zip_code"
city_data = left_join(city_data,complain_zip, by = "zip_code")
View(city_data)
?subset
1&2
1&2&
3&4
unique(city_data$Borough)
city_data$Borough = as.character(city_data$Borough)
unique(city_data$Borough)
plot_data = subset(city_data,population>=min_pop & population<=max_pop &
complain>=min_complain & complain<=max_complain &
metro_convenience %in% transportation &
security %in%  afety & Borough %in% borough)
max_complain = max(city_data$complain)
min_complain = 0
max_pop = max(city_data$population)
min_pop = 0
transportation = c("convenient","inconvenient","intermediate")
safety = c("safe","unsafe","intermediate")
borough = c("Manhattan","Staten Island", "Bronx","Queens","Brooklyn")
max_price = max(city_data$price)
min_price = -1
plot_data = subset(city_data,population>=min_pop & population<=max_pop &
complain>=min_complain & complain<=max_complain &
metro_convenience %in% transportation &
security %in%  afety & Borough %in% borough)
plot_data = subset(city_data,population>=min_pop & population<=max_pop &
complain>=min_complain & complain<=max_complain &
metro_convenience %in% transportation &
security %in%  safety & Borough %in% borough)
setwd("C:/Users/oweni/OneDrive/Documents/GitHub/EDAV_proj3/crimedata")
library(maptools)
zip.map <- readShapeSpatial("maps/tl_2010_36_zcta510.shp")
zips = read.csv("zip_map.csv")
ny.zip = zip.map[zip.map@data$ZCTA5CE10 %in% zips$ZIP.CODE,]
zip_mapping = data.frame(zip_code = as.numeric(as.character(ny.zip@data$ZCTA5CE10)),
long = as.numeric(as.character(ny.zip@data$INTPTLON10)),
lat = as.numeric(as.character(ny.zip@data$INTPTLAT10)))
View(zip_mapping)
write.csv(zip_mapping,"zip_mapping.csv",row.names = F)
setwd("C:/Users/oweni/OneDrive/Documents/GitHub/EDAV_proj3/citydata")
zip_mapping = read.csv("zip_mapping.csv")
if(dim(plot_data)[1]>0){
zip = plot_data$zip_code
zip = left_join(zip , zip_mapping , by = "zip_code")
}
zip = as.numeric(plot_data$zip_code)
zip = left_join(zip , zip_mapping , by = "zip_code")
str(zip)
zip = data.frame(zip_code = plot_data$zip_code)
zip = left_join(zip , zip_mapping , by = "zip_code")
View(zip)
setwd("C:/Users/oweni/OneDrive/Documents/GitHub/EDAV_proj3/citydata")
city_data = read.csv("NYC_data.csv")
city_data = city_data[city_data$population>0,]
library(ggplot2)
# analysis to set thresholds
ggplot(city_data,aes(x = metro))+geom_histogram(stat = "bin",binwidth=1)+
ggtitle("Distribution of Number of Metro stations")
met33 = quantile(city_data$metro,probs = 0.33)
met67 = quantile(city_data$metro,probs = 0.67)
city_data$metro_convenience = "inconvenient"
city_data$metro_convenience[city_data$metro>=met67] = "convenient"
city_data$metro_convenience[city_data$metro<met67 & city_data$metro>=met33] = "intermediate"
crime33 = quantile(city_data$crime_rate,probs = 0.33)
crime67 = quantile(city_data$crime_rate,probs = 0.67)
city_data$security = "unsafe"
city_data$security[city_data$crime_rate>=crime67] = "safe"
city_data$security[city_data$crime_rate<crime67 & city_data$crime_rate>=crime33] = "intermediate"
complain = read.csv("complain data(1,4,7,10).csv")
library(dplyr)
group_comp = group_by(complain,zip)
complain_zip = summarize(group_comp,complain = n())
names(complain_zip)[1] = "zip_code"
city_data = left_join(city_data,complain_zip, by = "zip_code")
city_data$Borough = as.character(city_data$Borough)
# default values
max_complain = max(city_data$complain)
min_complain = 0
max_pop = max(city_data$population)
min_pop = 0
transportation = c("convenient","inconvenient","intermediate")
safety = c("safe","unsafe","intermediate")
borough = c("Manhattan","Staten Island", "Bronx","Queens","Brooklyn")
max_price = max(city_data$price)
min_price = -1
plot_data = subset(city_data,population>=min_pop & population<=max_pop &
complain>=min_complain & complain<=max_complain &
metro_convenience %in% transportation &
security %in%  safety & Borough %in% borough)
# find the center of the plot
zip_mapping = read.csv("zip_mapping.csv")
if(dim(plot_data)[1]>0){
zip = data.frame(zip_code = plot_data$zip_code)
zip = left_join(zip , zip_mapping , by = "zip_code")
center = c(mean(zip$long),mean(zip$lat))
}
